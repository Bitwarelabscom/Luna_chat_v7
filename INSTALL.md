# Luna Chat - Installation Guide

Complete guide to deploying the Luna ecosystem from scratch.

## Architecture Overview

Luna consists of three interconnected services:

```
                    +-------------------+
                    |   Luna Frontend   |  (Next.js :3004)
                    +--------+----------+
                             |
                    +--------v----------+
                    |     Luna API      |  (Express :3005)
                    +---+------+--------+
                        |      |
           +------------+      +------------+
           |                                |
  +--------v---------+           +---------v---------+
  |    MemoryCore     |           |    NeuralSleep     |
  |  (Node.js :3007)  |           |   (Python/Flask)   |
  +---+----------+----+           +--+-+-+-+-----------+
      |          |                   | | | |
  Postgres    Redis             Semantic Episodic Working Consciousness
  (pgvector)                    (:5000)  (:5001)  (:5002) (:5003)
```

### Supporting Services

| Service | Purpose | Image |
|---------|---------|-------|
| **luna-postgres** | Main DB with pgvector | `pgvector/pgvector:pg15` |
| **luna-redis** | Caching, sessions, pub/sub | `redis:7-alpine` |
| **luna-neo4j** | Knowledge graph | `neo4j:5.15-community` |
| **luna-ollama** | Local LLM + embeddings | `ollama/ollama:latest` |
| **luna-radicale** | CalDAV/CardDAV server | `python:3.12-slim` |
| **luna-sandbox** | Code execution sandbox | Custom (Python/Node/Go/Rust) |
| **docker-proxy** | Secure Docker socket proxy | `tecnativa/docker-socket-proxy:edge` |
| **searxng** | Privacy-respecting search | `searxng/searxng:latest` |
| **tradecore** | Trading engine (Go) | Custom |

---

## Prerequisites

### System Requirements

- **OS**: Linux (Debian/Ubuntu recommended)
- **RAM**: 16 GB minimum, 32 GB recommended
- **Disk**: 50 GB+ free space (Docker images + volumes)
- **CPU**: 4+ cores recommended
- **Docker**: 24.0+ with Compose v2
- **Node.js**: 20 LTS (for local builds)
- **Git**: 2.30+

### API Keys (Required)

At minimum you need **one** LLM provider. All others are optional.

| Secret | Required | Purpose |
|--------|----------|---------|
| `openai_api_key` | Yes* | GPT models |
| `anthropic_api_key` | No | Claude models |
| `groq_api_key` | No | Fast inference (used for sentiment analysis) |
| `xai_api_key` | No | Grok models |
| `google_api_key` | No | Gemini models |
| `openrouter_api_key` | No | Multi-model router |
| `moonshot_api_key` | No | Moonshot AI |
| `elevenlabs_api_key` | No | Text-to-speech |
| `spotify_client_id` | No | Spotify integration |
| `spotify_client_secret` | No | Spotify integration |

*Or any other provider - at least one LLM key is needed.

### API Keys (Auto-generated)

These are generated by the install script:

| Secret | Purpose |
|--------|---------|
| `postgres_password` | PostgreSQL authentication |
| `jwt_secret` | JWT token signing (64 chars) |
| `redis_password` | Redis authentication |
| `neo4j_password` | Neo4j authentication |
| `encryption_key` | AES-256-GCM for OAuth tokens |

---

## Quick Start

```bash
# 1. Clone all three repositories
git clone https://github.com/Bitwarelabscom/Luna_chat_v7.git luna-chat
git clone https://github.com/Bitwarelabscom/memorycore.git memorycore
git clone https://github.com/Bitwarelabscom/neuralsleep.git neuralsleep

# 2. Run the install script
cd luna-chat
chmod +x scripts/install.sh
./scripts/install.sh

# 3. Follow the prompts to enter API keys

# 4. Start everything
./scripts/start.sh
```

---

## Manual Installation

### Step 1: Clone Repositories

All three repos should live in the same parent directory:

```bash
mkdir -p /opt && cd /opt
git clone https://github.com/Bitwarelabscom/Luna_chat_v7.git luna-chat
git clone https://github.com/Bitwarelabscom/memorycore.git memorycore
git clone https://github.com/Bitwarelabscom/neuralsleep.git neuralsleep
```

Expected layout:

```
/opt/
  luna-chat/          # Main application
  memorycore/         # Memory consolidation API
  neuralsleep/        # LNN neural network services
```

### Step 2: Create Docker Secrets

Luna uses Docker secrets instead of environment variables for sensitive values.

```bash
cd /opt/luna-chat
mkdir -p secrets

# Generate random secrets
openssl rand -hex 32 > secrets/postgres_password.txt
openssl rand -hex 32 > secrets/jwt_secret.txt
openssl rand -hex 32 > secrets/redis_password.txt
openssl rand -hex 32 > secrets/neo4j_password.txt
openssl rand -hex 32 > secrets/encryption_key.txt

# Add your API keys (replace with real values)
echo "sk-your-openai-key" > secrets/openai_api_key.txt
echo "sk-ant-your-anthropic-key" > secrets/anthropic_api_key.txt
echo "gsk_your-groq-key" > secrets/groq_api_key.txt
echo "xai-your-key" > secrets/xai_api_key.txt
echo "your-google-key" > secrets/google_api_key.txt
echo "your-openrouter-key" > secrets/openrouter_api_key.txt
echo "your-moonshot-key" > secrets/moonshot_api_key.txt
echo "your-elevenlabs-key" > secrets/elevenlabs_api_key.txt

# Email (optional - set empty if not using)
echo "" > secrets/email_password.txt

# Spotify (optional - set empty if not using)
echo "" > secrets/spotify_client_id.txt
echo "" > secrets/spotify_client_secret.txt

# IP allowlist (comma-separated, or empty for no restriction)
echo "" > secrets/allowed_ips.txt

# Remove trailing newlines (important for secrets)
for f in secrets/*.txt; do
  printf '%s' "$(cat "$f")" > "$f"
done
```

### Step 3: Create Environment File

```bash
cd /opt/luna-chat
cat > .env << 'EOF'
# Auto-generated secrets are read from secrets/*.txt files
# Only non-secret configuration goes here

# Agent Engine
AGENT_ENGINE=layered_v1

# Router Architecture
ROUTER_ENABLED=true

# Neo4j (password comes from secrets/neo4j_password.txt but also needed here for compose)
NEO4J_PASSWORD=<paste value from secrets/neo4j_password.txt>
NEO4J_ENABLED=true

# LLM Providers (toggle on/off)
GROQ_ENABLED=true
ANTHROPIC_ENABLED=true
XAI_ENABLED=true
GOOGLE_ENABLED=true
MOONSHOT_ENABLED=true

# ElevenLabs TTS
ELEVENLABS_ENABLED=false

# Ollama (local models)
OLLAMA_EMBEDDING_MODEL=bge-m3

# Encryption key (also needed in env for non-secret usage)
ENCRYPTION_KEY=<paste value from secrets/encryption_key.txt>

# Email (set to false to disable)
EMAIL_ENABLED=false
EMAIL_GATEKEEPER_ENABLED=false

# SearXNG
SEARXNG_ENABLED=true

# MemoryCore
MEMORYCORE_ENABLED=true

# TradeCore (set to false unless you have the trading engine)
TRADECORE_ENABLED=false
TRADECORE_MOCK_MODE=true

# Sanhedrin A2A (optional - requires Claude Code CLI credentials)
SANHEDRIN_ENABLED=false
EOF
```

### Step 4: Start NeuralSleep (First)

NeuralSleep must start first because MemoryCore connects to its network.

```bash
cd /opt/neuralsleep

# Build and start
docker compose up -d

# Wait for migrations to complete
docker compose logs -f migrations

# Verify all services are healthy
docker compose ps
```

Expected healthy services:
- `neuralsleep-postgres` (healthy)
- `neuralsleep-redis` (healthy)
- `neuralsleep-semantic` (healthy)
- `neuralsleep-episodic` (healthy)
- `neuralsleep-working` (healthy)
- `neuralsleep-consciousness` (healthy)

### Step 5: Start SearXNG

SearXNG runs as a separate compose stack. Luna connects to its Docker network.

```bash
cd /opt/searxng

# Create minimal compose file if not present
mkdir -p searxng
cat > docker-compose.yaml << 'EOF'
services:
  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "0.0.0.0:8888:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=http://localhost:8888/
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
EOF

docker compose up -d
```

### Step 6: Start MemoryCore

```bash
cd /opt/memorycore

# Build and start
docker compose up -d

# Verify
docker compose ps
```

Expected healthy services:
- `memorycore-postgres` (healthy)
- `memorycore-redis` (healthy)
- `memorycore-api` (running)

### Step 7: Build and Start Luna Chat

```bash
cd /opt/luna-chat

# Install Node.js dependencies (needed for build)
npm ci

# Build backend (TypeScript -> JavaScript)
npm run build:prod

# Build frontend
cd frontend
npm ci
npm run build
cd ..

# Build all Docker images
docker compose build

# Start everything
docker compose up -d
```

### Step 8: Pull Ollama Models

Luna uses Ollama for embeddings and local model inference.

```bash
# Pull the embedding model (required)
docker exec luna-ollama ollama pull bge-m3

# Pull a small model for email gatekeeper (optional)
docker exec luna-ollama ollama pull qwen2.5:3b
```

### Step 9: Run Database Migrations

Luna runs migrations automatically on startup, but you can also run them manually:

```bash
cd /opt/luna-chat
# Migrations run automatically via the API startup
# Check logs to verify:
docker logs luna-api 2>&1 | head -50
```

### Step 10: Verify Installation

```bash
# Check all services are healthy
docker ps --format "table {{.Names}}\t{{.Status}}" | sort

# Test Luna API health
curl http://localhost:3005/api/health

# Test MemoryCore API
curl http://localhost:3007/health

# Test NeuralSleep services
curl http://localhost:5000/health  # semantic
curl http://localhost:5001/health  # episodic
curl http://localhost:5002/health  # working
curl http://localhost:5003/health  # consciousness

# Test SearXNG
curl http://localhost:8888/
```

---

## Network Architecture

Luna uses several Docker networks for inter-service communication:

| Network | Services | Purpose |
|---------|----------|---------|
| `luna-network` | All Luna services | Internal communication |
| `searxng_default` | luna-api, searxng | Web search |
| `memorycore_memorycore-network` | luna-api, memorycore | Memory consolidation |
| `neuralsleep_neuralsleep-net` | memorycore, neuralsleep | LNN processing |
| `docker-proxy` | luna-api, docker-proxy | Sandbox execution |

The external networks (`searxng_default`, `memorycore_memorycore-network`, `neuralsleep_neuralsleep-net`) are created automatically by their respective docker-compose stacks. Luna Chat's compose file references them as `external: true`, which is why the other stacks must start first.

---

## Port Reference

### Exposed to Host

| Port | Service | Notes |
|------|---------|-------|
| 3004 | luna-frontend | Web UI |
| 3005 | luna-api | API (bound to 10.0.0.2 by default) |
| 3007 | memorycore-api | Exposed on 127.0.0.1 |
| 5000-5003 | neuralsleep LNNs | Exposed on 127.0.0.1 |
| 5434 | memorycore-postgres | Exposed on 127.0.0.1 |
| 5435 | neuralsleep-postgres | Exposed on 127.0.0.1 |
| 8888 | searxng | Web search UI |

### Internal Only (not exposed)

| Port | Service |
|------|---------|
| 5232 | luna-radicale (CalDAV) |
| 7474/7687 | luna-neo4j |
| 9090 | tradecore |
| 8000 | luna-sanhedrin |

---

## Customization

### Binding to a Different IP

The default config binds luna-api to `10.0.0.2`. To change this, edit `docker-compose.yml`:

```yaml
luna-api:
  ports:
    - "YOUR_IP:3005:3003"
```

Also update these env vars in `docker-compose.yml`:
- `CORS_ORIGIN`
- `OAUTH_CALLBACK_BASE_URL`
- `FRONTEND_URL`

And the frontend build arg:
```yaml
luna-frontend:
  build:
    args:
      - NEXT_PUBLIC_API_URL=http://YOUR_IP:3005
```

### Nginx Reverse Proxy (Recommended for Production)

For production, put nginx in front:

```nginx
server {
    listen 443 ssl http2;
    server_name luna.yourdomain.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    # Frontend
    location / {
        proxy_pass http://127.0.0.1:3004;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # API
    location /api/ {
        proxy_pass http://127.0.0.1:3005;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # WebSocket (editor collaboration)
    location /ws/ {
        proxy_pass http://127.0.0.1:3005;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # Socket.IO (chat real-time)
    location /socket.io/ {
        proxy_pass http://127.0.0.1:3005;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### Disabling Optional Services

Edit `docker-compose.yml` to comment out services you don't need:

- **tradecore** - Trading engine (disable unless you use trading features)
- **luna-sanhedrin** - A2A multi-agent coordination (requires Claude CLI credentials)
- **luna-mobile** - Mobile frontend variant
- **luna-sandbox** - Code execution sandbox

Also set corresponding env vars to `false`:
```bash
TRADECORE_ENABLED=false
SANHEDRIN_ENABLED=false
```

### MemoryCore Database Credentials

MemoryCore uses hardcoded dev credentials by default. For production, update `/opt/memorycore/docker-compose.yml`:

```yaml
environment:
  POSTGRES_PASSWORD: <strong-password>
  REDIS_PASSWORD: <strong-password>
```

Same for NeuralSleep in `/opt/neuralsleep/docker-compose.yml`.

---

## Updating

### Pulling Code Changes

```bash
# Luna Chat
cd /opt/luna-chat
git pull
npm ci
npm run build:prod
cd frontend && npm ci && npm run build && cd ..
docker compose build luna-api luna-frontend
docker compose up -d luna-api luna-frontend

# MemoryCore
cd /opt/memorycore
git pull
docker compose build api
docker compose up -d api

# NeuralSleep
cd /opt/neuralsleep
git pull
docker compose build
docker compose up -d
```

### Running New Migrations

Luna Chat runs migrations automatically on API startup. For MemoryCore and NeuralSleep, migrations are run via their respective init containers or entrypoint scripts.

---

## Troubleshooting

### External Network Not Found

```
ERROR: Network searxng_default declared as external, but could not be found
```

Fix: Start the dependent stack first (SearXNG, MemoryCore, or NeuralSleep).

### MemoryCore Connection Refused

Luna API logs: `ECONNREFUSED memorycore-api:3002`

Fix: Ensure MemoryCore is running and on the `memorycore_memorycore-network`:
```bash
docker network ls | grep memorycore
docker compose -f /opt/memorycore/docker-compose.yml up -d
```

### Neo4j Fails to Start

Neo4j needs time to initialize (60s start period). Check logs:
```bash
docker logs luna-neo4j
```

Common issue: APOC plugin download failure. Ensure the container has internet access.

### Ollama Model Not Found

```bash
docker exec luna-ollama ollama list  # Check installed models
docker exec luna-ollama ollama pull bge-m3  # Pull missing model
```

### Database Migration Errors

```bash
# Check Luna API logs for migration output
docker logs luna-api 2>&1 | grep -i migrat

# Manually run migrations
docker exec luna-api node dist/db/migrate.js
```

### Container Health Check Failures

```bash
# Check specific container logs
docker logs <container-name> --tail 50

# Check resource usage
docker stats --no-stream
```

---

## Complete Service Start Order

For a clean start from scratch:

```
1. neuralsleep      (creates neuralsleep_neuralsleep-net)
2. searxng          (creates searxng_default)
3. memorycore       (creates memorycore_memorycore-network, joins neuralsleep-net)
4. luna-chat        (joins all external networks)
```

This order matters because Luna Chat's docker-compose references external networks that must already exist.
